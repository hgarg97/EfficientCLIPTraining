{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwwBXvIbUXA_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Contrastive Language-Image Pretraining with SogCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVyLXcCiUkeF"
   },
   "source": [
    "### **Introduction**\n",
    "\n",
    "In this tutorial, you will learn how to conduct contrastive language-image pretraining by optimizing the [Global Contrastive Loss](https://arxiv.org/abs/2202.12387) (GCL) on a subset of the [Conceptual Captions](https://ai.google.com/research/ConceptualCaptions/) dataset. Also, you will learn how to evaluate the model on retrieval task using the [MSCOCO](https://cocodataset.org/#home) dataset and zero-shot classification task using the [ImageNet](https://www.image-net.org/challenges/LSVRC/index.php) dataset. The code is based on [iSogCLR's](https://github.com/zhqiu/contrastive-learning-iSogCLR) codebase, which includes the implementation of CLIP, SogCLR and iSogCLR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsO954DCVdgn"
   },
   "source": [
    "### Preparation\n",
    "\n",
    "First, we:\n",
    "\n",
    "1. Download the source code and data\n",
    "2. Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from gdown) (2.32.3)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, gdown\n",
      "Successfully installed gdown-5.2.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3wc5FDn51l6",
    "outputId": "37432b0a-04e8-4b1f-a518-4d8d3c7b9e75"
   },
   "outputs": [],
   "source": [
    "#!git clone -b project https://github.com/hgarg97/EfficientCLIPTraining.git iSogCLR\n",
    "\n",
    "!export PYTHONPATH=\"$PYTHONPATH:./iSogCLR/bimodal_exps\"\n",
    "!export HUGGINGFACE_HUB_CACHE='./checkpoints/huggingface'\n",
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9Z9qAdsaq8Y",
    "outputId": "3a5f71ab-b53e-45ef-a7e8-b53d55d78ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Creating datasets folder\n",
    "\n",
    "!mkdir datasets\n",
    "print(1)\n",
    "!mkdir -p datasets/imagenet\n",
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xM1XaqqTaW1n",
    "outputId": "0b3674d9-56eb-4dca-ac9a-e829f1adbb78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1riKYZDPW2QQLTKX4OWDZK7CpCfM5MLg6\n",
      "To: /scratch/user/hgarg97/dlProjectClip/clip_train.tar.gz\n",
      "100%|██████████████████████████████████████| 4.06M/4.06M [00:00<00:00, 27.4MB/s]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Downloading and Unzipping clip.tar.gz file\n",
    "\n",
    "!gdown 1riKYZDPW2QQLTKX4OWDZK7CpCfM5MLg6    # clip.tar.gz\n",
    "\n",
    "!tar xf clip_train.tar.gz\n",
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPQulAEdaw3d",
    "outputId": "1ff7fb0d-4f5c-41f7-f690-a9a4391586b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=17lYK5zF0GpSZVXlMcPOHD_nucA2qtdrz\n",
      "From (redirected): https://drive.google.com/uc?id=17lYK5zF0GpSZVXlMcPOHD_nucA2qtdrz&confirm=t&uuid=c9038775-d52b-49d8-bcc3-e62873c166f3\n",
      "To: /scratch/user/hgarg97/dlProjectClip/cc3m_subset_100k.tar.gz\n",
      "100%|███████████████████████████████████████| 3.07G/3.07G [00:18<00:00, 165MB/s]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Downloading and Unzipping cc3m_subset_100k.tar.gz file\n",
    "\n",
    "!gdown 17lYK5zF0GpSZVXlMcPOHD_nucA2qtdrz    # cc3m_subset_100k.tar.gz\n",
    "\n",
    "!tar xf cc3m_subset_100k.tar.gz -C datasets\n",
    "print(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wICT96ymbA1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1XK6L_jV1ImBzLi4_7tOG7gYCJBjzHWzv\n",
      "From (redirected): https://drive.google.com/uc?id=1XK6L_jV1ImBzLi4_7tOG7gYCJBjzHWzv&confirm=t&uuid=911b6d19-65e8-4ed6-b6d2-e21881b7c0b2\n",
      "To: /scratch/user/hgarg97/dlProjectClip/mscoco_val.tar.gz\n",
      "100%|█████████████████████████████████████████| 819M/819M [00:05<00:00, 159MB/s]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Downloading and Unzipping ms_coco_val.tar.gz file\n",
    "\n",
    "!gdown 1XK6L_jV1ImBzLi4_7tOG7gYCJBjzHWzv    # ms_coco_val.tar.gz\n",
    "\n",
    "!tar xf mscoco_val.tar.gz -C datasets\n",
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kuGetVZ2V2Wa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-gT5tg3t39TbZ68jd7YpUrHsXmDO-xCy\n",
      "From (redirected): https://drive.google.com/uc?id=1-gT5tg3t39TbZ68jd7YpUrHsXmDO-xCy&confirm=t&uuid=49400df1-2cb8-4222-9ab6-e6f7ba0ebc61\n",
      "To: /scratch/user/hgarg97/dlProjectClip/val.tar\n",
      "100%|███████████████████████████████████████| 6.75G/6.75G [00:41<00:00, 161MB/s]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Downloading and Unzipping val.tar file\n",
    "\n",
    "!gdown 1-gT5tg3t39TbZ68jd7YpUrHsXmDO-xCy    # val.tar\n",
    "\n",
    "!tar xf val.tar -C datasets/imagenet\n",
    "print(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NVqecTtSchT8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting braceexpand==0.1.7 (from -r ./iSogCLR/requirements.txt (line 2))\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting certifi==2023.7.22 (from -r ./iSogCLR/requirements.txt (line 3))\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.0 (from -r ./iSogCLR/requirements.txt (line 4))\n",
      "  Downloading charset_normalizer-3.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
      "Collecting colorama==0.4.6 (from -r ./iSogCLR/requirements.txt (line 5))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting filelock==3.12.4 (from -r ./iSogCLR/requirements.txt (line 6))\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec==2023.9.2 (from -r ./iSogCLR/requirements.txt (line 7))\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting ftfy==6.1.1 (from -r ./iSogCLR/requirements.txt (line 8))\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting huggingface-hub==0.16.4 (from -r ./iSogCLR/requirements.txt (line 9))\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting idna==3.4 (from -r ./iSogCLR/requirements.txt (line 10))\n",
      "  Downloading idna-3.4-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting Jinja2==3.1.2 (from -r ./iSogCLR/requirements.txt (line 11))\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: MarkupSafe==2.1.3 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from -r ./iSogCLR/requirements.txt (line 12)) (2.1.3)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from -r ./iSogCLR/requirements.txt (line 13)) (1.3.0)\n",
      "Collecting networkx==3.1 (from -r ./iSogCLR/requirements.txt (line 14))\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting numpy==1.26.0 (from -r ./iSogCLR/requirements.txt (line 15))\n",
      "  Downloading numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting packaging==23.2 (from -r ./iSogCLR/requirements.txt (line 16))\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.1.1 (from -r ./iSogCLR/requirements.txt (line 17))\n",
      "  Downloading pandas-2.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting Pillow==10.0.1 (from -r ./iSogCLR/requirements.txt (line 18))\n",
      "  Downloading Pillow-10.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting pip==23.2.1 (from -r ./iSogCLR/requirements.txt (line 19))\n",
      "  Downloading pip-23.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyreadline3==3.4.1 (from -r ./iSogCLR/requirements.txt (line 20))\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-dateutil==2.8.2 (from -r ./iSogCLR/requirements.txt (line 21))\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting pytz==2023.3.post1 (from -r ./iSogCLR/requirements.txt (line 22))\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.1 (from -r ./iSogCLR/requirements.txt (line 23))\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex==2023.10.3 (from -r ./iSogCLR/requirements.txt (line 24))\n",
      "  Downloading regex-2023.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests==2.31.0 (from -r ./iSogCLR/requirements.txt (line 25))\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors==0.3.3 (from -r ./iSogCLR/requirements.txt (line 26))\n",
      "  Downloading safetensors-0.3.3.tar.gz (35 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setuptools==68.2.2 (from -r ./iSogCLR/requirements.txt (line 27))\n",
      "  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /scratch/user/hgarg97/.conda/envs/dlEnv/lib/python3.12/site-packages (from -r ./iSogCLR/requirements.txt (line 28)) (1.16.0)\n",
      "Collecting sympy==1.12 (from -r ./iSogCLR/requirements.txt (line 29))\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting timm==0.9.7 (from -r ./iSogCLR/requirements.txt (line 30))\n",
      "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
      "Collecting tokenizers==0.14.0 (from -r ./iSogCLR/requirements.txt (line 31))\n",
      "  Downloading tokenizers-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.1+cu118 (from versions: 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0, 2.3.1, 2.3.1+cpu, 2.3.1+cpu.cxx11.abi, 2.3.1+cu118, 2.3.1+cu121, 2.3.1+rocm5.7, 2.3.1+rocm6.0, 2.4.0, 2.4.1, 2.5.0, 2.5.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.1+cu118\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Installing libraries\n",
    "\n",
    "!pip install -r ./iSogCLR/requirements.txt    # there may be pip warnings/ errors, should be fine to ignore them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11x28L3vV2od"
   },
   "source": [
    "# Training\n",
    "\n",
    "The following command runs the training script to train a ResNet50 (pretrained on ImageNet) and a DistilBERT (pretrained on BookCorpus and English Wikipedia) on the cc3m dataset using the SogCLR loss for 30 epochs with temperature 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHsfHktfb883"
   },
   "source": [
    "## isogclr_new_v2 + radam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9y3Do55rK8wX"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4BjOwHiWP2u",
    "outputId": "ff1bf5b1-2752-457a-8470-c9cbeea1afe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating retrieval dataset\n",
      "len of train_dataset: 100000\n",
      "len of coco val: 5000\n",
      "Downloading tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 286kB/s]\n",
      "Downloading config.json: 100% 483/483 [00:00<00:00, 3.05MB/s]\n",
      "Downloading vocab.txt: 100% 232k/232k [00:00<00:00, 1.10MB/s]\n",
      "Downloading tokenizer.json: 100% 466k/466k [00:00<00:00, 32.8MB/s]\n",
      "Creating model\n",
      "Downloading model.safetensors: 100% 102M/102M [00:00<00:00, 237MB/s] \n",
      "Downloading model.safetensors: 100% 268M/268M [00:01<00:00, 241MB/s]\n",
      "Start training\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/./iSogCLR/bimodal_exps/clip.py\", line 710, in <module>\n",
      "    main(args)\n",
      "  File \"/content/./iSogCLR/bimodal_exps/clip.py\", line 501, in main\n",
      "    train_stats = train(model, train_loader, optimizer, tokenizer, epoch, max_epoch, warmup_steps, device, lr_scheduler, \n",
      "  File \"/content/./iSogCLR/bimodal_exps/clip.py\", line 66, in train\n",
      "    for i,(image, text, idx, text_idx) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
      "  File \"/content/iSogCLR/bimodal_exps/utils.py\", line 137, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 715, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n",
      "    data = self.dataset.__getitems__(possibly_batched_index)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "  File \"/content/iSogCLR/bimodal_exps/dataset/caption_dataset.py\", line 40, in __getitem__\n",
      "    image = Image.open(image_path).convert('RGB')\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3469, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/content/datasets/cc3m_subset_100k/cc_data/train/522/884522.jpg'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
    "    --data_path ./datasets \\\n",
    "    --ann_path ./clip_train \\\n",
    "    --train_file cc3m_train_subset.json \\\n",
    "    --train_image_root cc3m_subset_100k \\\n",
    "    --output_dir output/isogclr_new_v2_and_radam \\\n",
    "    --init_model \\\n",
    "    --use_amp \\\n",
    "    --ita_type isogclr_new_v2 \\\n",
    "    --tau_init 0.01 \\\n",
    "    --sogclr_gamma 0.8 \\\n",
    "    --eta_init 0.03 --sched cosine \\\n",
    "    --no-distributed \\\n",
    "    --epochs 30 \\\n",
    "    --opt radam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmCh9QFuWx-t"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "The following command runs the evaluation script to evaluate the retrieval performance of the trained model on the MSCOCO validation dataset and the zero-shot classification performance on the ImageNet validation dataset. The evaluation command is obtained by appending `--evaluate --checkpoint /path/to/your/checkpoint --zs_dataset imagenet --zs_datafolder /path/to/imagenet/val` to the training command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdSq-cQwoork"
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
    "    --data_path ./datasets \\\n",
    "    --ann_path ./clip_train \\\n",
    "    --train_file cc3m_train_subset.json \\\n",
    "    --train_image_root cc3m_subset_100k \\\n",
    "    --output_dir output/isogclr_new_v2_and_radam \\\n",
    "    --init_model \\\n",
    "    --use_amp \\\n",
    "    --ita_type isogclr_new_v2 \\\n",
    "    --tau_init 0.01 \\\n",
    "    --sogclr_gamma 0.8 \\\n",
    "    --eta_init 0.03 --sched cosine \\\n",
    "    --no-distributed \\\n",
    "    --epochs 30 \\\n",
    "    --evaluate --checkpoint './output/isogclr_new_v2_and_radam/checkpoint_30.pth' \\\n",
    "    --zs_dataset imagenet --zs_datafolder ./datasets/imagenet/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4tw47loXXPK"
   },
   "source": [
    "### Benchmarks\n",
    "\n",
    "The following results are recall at 1 results on the provided MSCOCO and ImageNet datasets. The first row of results are from the model trained using the CLIP loss, and the second row of results are from the model trained using the SogCLR loss. All results are based on a batch size of 128 for 30-epoch pretraining. IR@1 denotes the recall at 1 of image retrieval on MSCOCO, TR@1 denotes the recall at 1 of text retrieval on MSCOCO, and ACC@1 denotes the top 1 accuracy on ImageNet. Average denotes the average of the three metrics.\n",
    "\n",
    "| Method | MSCOCO TR@1 | MSCOCO IR@1 | ImageNet ACC@1 | Average |\n",
    "|:----------:|:--------:|:--------:|:--------:|:--------:|\n",
    "| CLIP | 12.0 | 9.32 | 21.35 | 14.22 |\n",
    "| SogCLR |  14.38  |  10.73  | 24.54 | 16.55 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
